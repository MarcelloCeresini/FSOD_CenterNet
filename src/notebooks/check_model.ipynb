{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=1.63s)\n",
      "creating index...\n",
      "index created!\n",
      "Skipping instantating novel head\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "import torch as T\n",
    "import yaml\n",
    "from torch.optim import Adam\n",
    "from tqdm import tqdm\n",
    "\n",
    "import sys\n",
    "\n",
    "sys.path.append('/home/volpepe/Desktop/FSOD_CenterNet/src')\n",
    "from data_pipeline import DatasetsGenerator\n",
    "from model import Model\n",
    "\n",
    "\n",
    "def load_settings(settings_path: str):\n",
    "    with open(settings_path, 'r') as f:\n",
    "        return yaml.safe_load(f)\n",
    "    \n",
    "settings = '../settings/model_testing_debug_check.yaml'\n",
    "    \n",
    "config = load_settings(settings)\n",
    "\n",
    "if os.path.exists(config['training']['save_base_weights_dir']) \\\n",
    "                and config[\"training\"][\"train_base\"] \\\n",
    "                and config[\"training\"][\"no_overwrite\"]:\n",
    "    raise ValueError(\"Cannot overwrite weights\")\n",
    "\n",
    "os.makedirs(config['training']['save_training_info_dir'], exist_ok=True)\n",
    "\n",
    "debug_mode = config['debug']['debug_mode_active']\n",
    "device = config['device']\n",
    "\n",
    "K = config['data']['K']\n",
    "val_K = config['data']['val_K']\n",
    "test_K = config['data']['test_K']\n",
    "n_repeats_novel_train = config['training']['repeat_novel_training']\n",
    "\n",
    "if isinstance(K, int): K = [K]\n",
    "if isinstance(val_K, int): val_K = [val_K]\n",
    "if isinstance(test_K, int): test_K = [test_K]\n",
    "\n",
    "# Dataset generator. Only one of these has to be instantiated. It always returns\n",
    "dataset_gen = DatasetsGenerator(config)\n",
    "\n",
    "if config['training']['train_base']:\n",
    "\n",
    "    # Instantiate the model (only the base part)\n",
    "    model = Model(config, n_base_classes=len(dataset_gen.train_base.cats))\n",
    "    model = model.to(device)\n",
    "\n",
    "    # Use the dataset generator to generate the base set\n",
    "    dataset_base_train, dataset_base_val, dataset_base_test = dataset_gen.get_base_sets_dataloaders(\n",
    "        config['training']['batch_size'], config['training']['num_workers'],\n",
    "        config['training']['pin_memory'], config['training']['drop_last'], \n",
    "        shuffle=True\n",
    "    )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(T.load('../../data/weights/from_server/best_model_fix.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13806677"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "params = sum([np.prod(p.size()) for p in model.parameters()])\n",
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11176512"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([np.prod(p.size()) for p in model.encoder.parameters()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (input_image, labels, n_detections, _) in enumerate(dataset_base_train):\n",
    "    out = model(input_image.to(device))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_reg, out_head_base, _ = out\n",
    "regressor_label, heatmap_base, _ = labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[10.1728, 12.6651,  0.5879,  0.5829],\n",
       "        [14.5293, 16.9659,  0.5041,  0.5115],\n",
       "        [12.3113, 14.4862,  0.5710,  0.5692],\n",
       "        [11.7774,  9.7300, 14.3218, 12.4755],\n",
       "        [ 0.5241,  0.5881,  0.5271,  0.5828]], device='cuda:0',\n",
       "       grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_reg[T.where(regressor_label != 0)].reshape(-1, 4)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3.2071e+01, 3.9691e+01, 4.3597e-01, 9.6491e-03],\n",
       "        [8.6848e+00, 4.7006e+00, 4.2223e-01, 6.9492e-01],\n",
       "        [1.0055e+01, 1.3155e+01, 2.5462e-01, 9.7897e-01],\n",
       "        [1.1757e+01, 1.9492e+01, 9.7176e+00, 1.0894e+01],\n",
       "        [6.3536e-01, 4.1989e-01, 5.2031e-01, 4.7195e-01]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressor_label[T.where(regressor_label != 0)].reshape(-1, 4)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0063, 0.0024, 0.0031, 0.0049, 0.0058], device='cuda:0',\n",
       "       grad_fn=<IndexBackward0>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_head_base[T.where(heatmap_base==1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.0232, device='cuda:0', grad_fn=<MaxBackward1>),\n",
       " tensor(0.0005, device='cuda:0', grad_fn=<MinBackward1>),\n",
       " tensor(0.0033, device='cuda:0', grad_fn=<MeanBackward0>))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_head_base.max(), out_head_base.min(), out_head_base.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(1.), tensor(0.), tensor(0.0005))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "heatmap_base.max(), heatmap_base.min(), heatmap_base.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def heatmap_loss(pred_heatmap, gt_heatmap, num_keypoints, config):\n",
    "    gt_heatmap = gt_heatmap.to(pred_heatmap.device)\n",
    "    num_keypoints = num_keypoints.to(pred_heatmap.device)\n",
    "\n",
    "    loss = T.where(\n",
    "        gt_heatmap == 1,\n",
    "        (1 - pred_heatmap) ** config['model']['alpha_loss'] * T.log(pred_heatmap),\n",
    "        (1 - gt_heatmap) ** config['model']['beta_loss'] * \\\n",
    "            (pred_heatmap) ** config['model']['alpha_loss'] * T.log(1 - pred_heatmap),\n",
    "    ).reshape(pred_heatmap.shape[0], -1).sum(dim=-1)\n",
    "\n",
    "    result = T.where(\n",
    "        num_keypoints != 0,\n",
    "        input = loss / num_keypoints,\n",
    "        other = 0\n",
    "    )\n",
    "\n",
    "    return -result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(-3.5904, device='cuda:0', grad_fn=<MaxBackward1>),\n",
       " tensor(-5.8532, device='cuda:0', grad_fn=<MeanBackward0>))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_heatmap = out_head_base\n",
    "gt_heatmap = heatmap_base\n",
    "num_keypoints = n_detections\n",
    "\n",
    "gt_heatmap = gt_heatmap.to(pred_heatmap.device)\n",
    "num_keypoints = num_keypoints.to(pred_heatmap.device)\n",
    "\n",
    "a1 = (1 - pred_heatmap) ** config['model']['alpha_loss'] * T.log(pred_heatmap)\n",
    "a2 = (1 - gt_heatmap) ** config['model']['beta_loss'] * (pred_heatmap) ** config['model']['alpha_loss'] * T.log(1 - pred_heatmap)\n",
    "\n",
    "a1.max(), a1.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 240, 8, 8])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(-1.0031e-07, device='cuda:0', grad_fn=<MeanBackward0>),\n",
       " tensor(-1.2655e-05, device='cuda:0', grad_fn=<MinBackward1>))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a2.mean(), a2.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5.0132, 5.9995, 5.7377, 5.1834], device='cuda:0',\n",
       "       grad_fn=<NegBackward0>)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "heatmap_loss(out_head_base, heatmap_base, n_detections, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.00010261713"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(32*32-1)*-1.0031e-07"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as NNF\n",
    "import torch as T\n",
    "from torchmetrics.detection import MeanAveragePrecision\n",
    "\n",
    "@T.no_grad()\n",
    "def get_heatmap_maxima_idxs(complete_heatmaps):\n",
    "    pooled_heatmaps = NNF.max_pool2d(complete_heatmaps,\n",
    "                                    3,\n",
    "                                    stride=1,\n",
    "                                    padding=1)\n",
    "    return (complete_heatmaps == pooled_heatmaps)\n",
    "\n",
    "def landmarks_from_idxs(regressor_pred: T.tensor,\n",
    "                        complete_heatmaps: T.tensor,\n",
    "                        idxs_tensor_mask: T.tensor):\n",
    "    n_classes, output_width, output_height = idxs_tensor_mask.shape\n",
    "\n",
    "    num_detections = T.sum(idxs_tensor_mask).to('cpu')\n",
    "    num_detections = min(10, num_detections)\n",
    "    \n",
    "    landmarks_pred = {\n",
    "        \"boxes\": T.zeros(num_detections,4),\n",
    "        \"labels\": T.zeros(num_detections).to(T.int32),\n",
    "        \"scores\": T.zeros(num_detections)\n",
    "    }\n",
    "\n",
    "    # Flattens it so we can use topk\n",
    "    confidence_scores = T.masked_select(complete_heatmaps, idxs_tensor_mask)\n",
    "\n",
    "    # The i-th element in top_k_scores has the i-th highest confidence score in the image, \n",
    "    # but its index refers to its position in \"confidence_scores\" (which is a flattened tensor\n",
    "    # tthat has as many elements as idxs_tensor_mask's true values, or peaks).\n",
    "    # Instead, we will need a n_classes*output_width*output_height tensor to get indices\n",
    "    top_k_scores = T.topk(confidence_scores, num_detections)\n",
    "    \n",
    "    # This retrieves all of the (flattened) indices (of the output image) where the classification has a peak\n",
    "    flattened_idxs = T.nonzero(T.flatten(idxs_tensor_mask)).reshape(-1)\n",
    "\n",
    "    # this retrieves only the top \"num_detections\" of them (but still, flattened)\n",
    "    flattened_top_k_idxs = flattened_idxs[top_k_scores.indices]\n",
    "\n",
    "    base_mask = T.zeros(n_classes*output_width*output_height).to(device='cuda')\n",
    "    # Populates the mask with 1s for topk indices\n",
    "    base_mask[flattened_top_k_idxs] += 1\n",
    "    mask = base_mask.to(dtype=T.bool)\n",
    "\n",
    "    top_k_mask = T.unflatten(mask, dim=0, sizes=(n_classes, output_width, output_height))\n",
    "    top_k_idxs = T.nonzero(top_k_mask)\n",
    "\n",
    "    print(top_k_idxs)\n",
    "\n",
    "    regressor_pred_repeated = regressor_pred.repeat(n_classes,1,1,1)\n",
    "\n",
    "    size_x = T.masked_select(regressor_pred_repeated[:,0,:,:],\n",
    "                                top_k_mask)\n",
    "    size_y = T.masked_select(regressor_pred_repeated[:,1,:,:],\n",
    "                                top_k_mask)\n",
    "    off_x = T.masked_select(regressor_pred_repeated[:,2,:,:],\n",
    "                                top_k_mask)\n",
    "    off_y = T.masked_select(regressor_pred_repeated[:,3,:,:],\n",
    "                                top_k_mask)\n",
    "\n",
    "    category = top_k_idxs[:,0]\n",
    "    center_idx_y = top_k_idxs[:,1]\n",
    "    center_idx_x = top_k_idxs[:,2]\n",
    "\n",
    "    center_coord_x = center_idx_x+off_x\n",
    "    center_coord_y = center_idx_y+off_y\n",
    "\n",
    "    for i, (c, cx, cy, sx, sy, score) in \\\n",
    "        enumerate(zip(category, center_coord_x, center_coord_y, size_x, size_y, confidence_scores)):\n",
    "\n",
    "            landmarks_pred[\"boxes\"][i,0] = cx\n",
    "            landmarks_pred[\"boxes\"][i,1] = cy\n",
    "            landmarks_pred[\"boxes\"][i,2] = sx\n",
    "            landmarks_pred[\"boxes\"][i,3] = sy\n",
    "            landmarks_pred[\"labels\"][i] = c\n",
    "            landmarks_pred[\"scores\"][i] = score\n",
    "\n",
    "    return landmarks_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[  8,  16,  15],\n",
      "        [ 95,  16,  13],\n",
      "        [ 95,  16,  15],\n",
      "        [100,  16,  15],\n",
      "        [110,  16,  15],\n",
      "        [132,  18,  15],\n",
      "        [137,  16,  15],\n",
      "        [150,  16,  15],\n",
      "        [187,  17,  15],\n",
      "        [187,  18,  13]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "for counter, (image_batch, _, n_landmarks_batch, padded_landmarks) in enumerate(dataset_base_train):\n",
    "\n",
    "    # both image and landmarks will be resized to model_input_size\n",
    "    reg_pred_batch, heat_base_pred_batch, heat_novel_pred_batch = model(image_batch.to('cuda'))\n",
    "\n",
    "    for i, (reg_pred, heat_base_pred, n_landmarks) in \\\n",
    "        enumerate(zip(reg_pred_batch, heat_base_pred_batch, n_landmarks_batch)):\n",
    "        complete_heatmaps = heat_base_pred\n",
    "\n",
    "        idxs_tensor = get_heatmap_maxima_idxs(complete_heatmaps)\n",
    "\n",
    "        landmarks_pred = landmarks_from_idxs(\n",
    "            reg_pred,\n",
    "            complete_heatmaps,\n",
    "            idxs_tensor\n",
    "        )\n",
    "\n",
    "        landmarks_gt = {\n",
    "            \"boxes\": padded_landmarks[\"boxes\"][i,:n_landmarks,:],\n",
    "            \"labels\": padded_landmarks[\"labels\"][i,:n_landmarks]\n",
    "        }\n",
    "    \n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'boxes': tensor([[67.8649, 56.3060, 61.1892, 38.9362]]),\n",
       " 'labels': tensor([41], dtype=torch.int32)}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "landmarks_gt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'boxes': tensor([[16.4100, 16.4538, 72.0674, 47.1962],\n",
       "         [16.5736, 15.6011, 71.1743, 49.0226],\n",
       "         [16.4100, 16.4538, 72.0674, 47.1962],\n",
       "         [16.4100, 16.4538, 72.0674, 47.1962],\n",
       "         [16.4100, 16.4538, 72.0674, 47.1962],\n",
       "         [16.4100, 16.4538, 72.0674, 47.1962],\n",
       "         [16.4100, 16.4538, 72.0674, 47.1962],\n",
       "         [16.4100, 16.4538, 72.0674, 47.1962],\n",
       "         [16.4100, 16.4538, 72.0674, 47.1962],\n",
       "         [16.4100, 16.4538, 72.0674, 47.1962]], grad_fn=<CopySlices>),\n",
       " 'labels': tensor([ 10,  15,  52, 111, 116, 117, 156, 157, 190, 195], dtype=torch.int32),\n",
       " 'scores': tensor([0.0025, 0.0020, 0.0017, 0.0016, 0.0023, 0.0022, 0.0022, 0.0028, 0.0027,\n",
       "         0.0021], grad_fn=<CopySlices>)}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "landmarks_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml4cv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
