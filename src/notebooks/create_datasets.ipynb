{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=3.60s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "from typing import Any, Dict, List, Optional\n",
    "\n",
    "import numpy as np\n",
    "from pycocotools.coco import COCO\n",
    "from tqdm import tqdm\n",
    "\n",
    "root_path = os.path.join('..', '..')\n",
    "full_annotation_file = os.path.join(root_path, 'data', 'full_2017_bboxes.json')\n",
    "novel_classes_file = os.path.join(root_path, 'data', 'novel_class_ids.json')\n",
    "base_classes_file = os.path.join(root_path, 'data', 'base_class_ids.json')\n",
    "\n",
    "coco_dset = COCO(full_annotation_file)\n",
    "coco_json = json.load(open(full_annotation_file, 'r'))\n",
    "with open(novel_classes_file, 'r') as f:\n",
    "    novel_classes = json.load(f)['novel_cat_ids']\n",
    "with open(base_classes_file, 'r') as f:\n",
    "    base_classes = json.load(f)['base_cat_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_SET_RATIOS = (80, 10, 10)\n",
    "BASE_SET_SMALL_RATIOS = (8, 1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sample images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_val_test_annots_and_imgs(small=False):\n",
    "    base_cat_to_imgs = {k: v for k, v in coco_dset.catToImgs.items() if k in base_classes}\n",
    "\n",
    "    train_set_base_imgs = []\n",
    "    val_set_base_imgs   = []\n",
    "    test_set_base_imgs  = []\n",
    "\n",
    "    for base_cat in base_cat_to_imgs:\n",
    "        imgs = set(base_cat_to_imgs[base_cat])\n",
    "        \n",
    "        n_sample_train  = int((BASE_SET_RATIOS[0] if not small else BASE_SET_SMALL_RATIOS[0]) / 100 * len(imgs))\n",
    "        n_sample_val    = int((BASE_SET_RATIOS[1] if not small else BASE_SET_SMALL_RATIOS[1]) / 100 * len(imgs))\n",
    "        n_sample_test   = int((BASE_SET_RATIOS[2] if not small else BASE_SET_SMALL_RATIOS[2]) / 100 * len(imgs))\n",
    "\n",
    "        train_imgs  = set(random.sample(sorted(imgs), n_sample_train))\n",
    "        imgs        = imgs.difference(train_imgs)\n",
    "        val_imgs    = set(random.sample(sorted(imgs), n_sample_val))\n",
    "        if not small:\n",
    "            test_imgs = imgs.difference(val_imgs)\n",
    "        else:\n",
    "            imgs = imgs.difference(val_imgs)\n",
    "            test_imgs = set(random.sample(sorted(imgs), n_sample_test))\n",
    "\n",
    "        train_set_base_imgs.extend(train_imgs)\n",
    "        val_set_base_imgs.extend(val_imgs)\n",
    "        test_set_base_imgs.extend(test_imgs)\n",
    "\n",
    "    print(\"Base images: \\ntrain, val,  set\")\n",
    "    print(len(train_set_base_imgs), len(val_set_base_imgs), len(test_set_base_imgs))\n",
    "\n",
    "    train_set = coco_dset.loadAnns(coco_dset.getAnnIds(imgIds=train_set_base_imgs))\n",
    "    val_set   = coco_dset.loadAnns(coco_dset.getAnnIds(imgIds=val_set_base_imgs))\n",
    "    test_set  = coco_dset.loadAnns(coco_dset.getAnnIds(imgIds=test_set_base_imgs))\n",
    "\n",
    "    print()\n",
    "    print(\"Base annotations: \\ntrain, val,  set\")\n",
    "    print(len(train_set), len(val_set), len(test_set))\n",
    "\n",
    "    return (train_set, val_set, test_set), \\\n",
    "        (coco_dset.loadImgs(train_set_base_imgs), \n",
    "         coco_dset.loadImgs(val_set_base_imgs), \n",
    "         coco_dset.loadImgs(test_set_base_imgs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LARGE DATASET\n",
      "Base images: \n",
      "train, val,  set\n",
      "170553 21216 21543\n",
      "\n",
      "Base annotations: \n",
      "train, val,  set\n",
      "223793 27873 28247\n",
      "\n",
      "\n",
      "\n",
      "SMALL DATASET\n",
      "Base images: \n",
      "train, val,  set\n",
      "16950 2013 2013\n",
      "\n",
      "Base annotations: \n",
      "train, val,  set\n",
      "22386 2637 2673\n"
     ]
    }
   ],
   "source": [
    "print(\"LARGE DATASET\")\n",
    "\n",
    "(train_annots, val_annots, test_annots), (train_imgs, val_imgs, test_imgs) = \\\n",
    "    get_train_val_test_annots_and_imgs(small=False)\n",
    "\n",
    "print('\\n\\n')\n",
    "print(\"SMALL DATASET\")\n",
    "\n",
    "(small_train_annots, small_val_annots, small_test_annots), \\\n",
    "    (small_train_imgs, small_val_imgs, small_test_imgs) = \\\n",
    "        get_train_val_test_annots_and_imgs(small=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save datasets into coco format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "coco_format = {\n",
    "    'info': coco_json['info'],\n",
    "    'licenses': coco_json['licenses'],\n",
    "    'categories': [c for c in coco_json['categories'] if c['id'] in base_classes],\n",
    "    'images': [],\n",
    "    'annotations': []\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "coco_format['images'] = train_imgs\n",
    "coco_format['annotations'] = train_annots\n",
    "with open(os.path.join(root_path, 'data', 'base_dset', 'base_train.json'), 'w') as f:\n",
    "    json.dump(coco_format, f)\n",
    "\n",
    "coco_format['images'] = val_imgs\n",
    "coco_format['annotations'] = val_annots\n",
    "with open(os.path.join(root_path, 'data', 'base_dset', 'base_val.json'), 'w') as f:\n",
    "    json.dump(coco_format, f)\n",
    "\n",
    "coco_format['images'] = test_imgs\n",
    "coco_format['annotations'] = test_annots\n",
    "with open(os.path.join(root_path, 'data', 'base_dset', 'base_test.json'), 'w') as f:\n",
    "    json.dump(coco_format, f)\n",
    "\n",
    "\n",
    "\n",
    "coco_format['images'] = small_train_imgs\n",
    "coco_format['annotations'] = small_train_annots\n",
    "with open(os.path.join(root_path, 'data', 'base_dset', 'small_base_train.json'), 'w') as f:\n",
    "    json.dump(coco_format, f)\n",
    "\n",
    "coco_format['images'] = small_val_imgs\n",
    "coco_format['annotations'] = small_val_annots\n",
    "with open(os.path.join(root_path, 'data', 'base_dset', 'small_base_val.json'), 'w') as f:\n",
    "    json.dump(coco_format, f)\n",
    "\n",
    "coco_format['images'] = small_test_imgs\n",
    "coco_format['annotations'] = small_test_annots\n",
    "with open(os.path.join(root_path, 'data', 'base_dset', 'small_base_test.json'), 'w') as f:\n",
    "    json.dump(coco_format, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml4cv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
